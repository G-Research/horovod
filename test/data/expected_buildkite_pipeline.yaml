steps:
- label: ':docker: Build test-cpu-gloo-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_0'
  plugins:
  - docker-compose#6b0df8a98ff97f42f4944dbb745b5b8cbf04b78c:
      build: test-cpu-gloo-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_0
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-gloo-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_0:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-gloo-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_0-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-openmpi-py3_6-tf1_14_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_4_0'
  plugins:
  - docker-compose#6b0df8a98ff97f42f4944dbb745b5b8cbf04b78c:
      build: test-cpu-openmpi-py3_6-tf1_14_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_4_0
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-openmpi-py3_6-tf1_14_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_4_0:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-openmpi-py3_6-tf1_14_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_4_0-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':book: Build Docs'
  command: 'cd /workdir/docs && pip install -r requirements.txt && make html'
  plugins:
  - docker#v3.1.0:
      image: 'python:3.7'
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- wait
- label: ':spark: PyTests Spark Estimators (test-cpu-gloo-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_0)'
  command: bash -c "cd /horovod/test && pytest --forked -v --capture=no test_spark_keras.py test_spark_torch.py"
  plugins:
  - docker-compose#v2.6.0:
      run: test-cpu-gloo-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_0
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':spark: PyTests Spark Estimators (test-cpu-openmpi-py3_6-tf1_14_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_4_0)'
  command: bash -c "cd /horovod/test && pytest --forked -v --capture=no test_spark_keras.py test_spark_torch.py"
  plugins:
  - docker-compose#v2.6.0:
      run: test-cpu-openmpi-py3_6-tf1_14_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_4_0
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
